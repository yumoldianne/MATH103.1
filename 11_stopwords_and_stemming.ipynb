{"cells":[{"source":"# 3.2 Stopwords and Lemmatization","metadata":{},"id":"98a2083e-203d-4b6b-83c8-7448b5782d58","cell_type":"markdown"},{"source":"import numpy as np\nimport pandas as pd\nimport re","metadata":{"executionCancelledAt":null,"executionTime":142,"lastExecutedAt":1697074504185,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import numpy as np\nimport pandas as pd\nimport re"},"id":"653e3292-424e-4bc6-9ca2-fceee6c87875","cell_type":"code","execution_count":1,"outputs":[]},{"source":"## Review: Tokenization with NLTK","metadata":{},"id":"bea54462-813c-4698-899f-b6b42a1fdc90","cell_type":"markdown"},{"source":"import nltk\nnltk.download('punkt')","metadata":{"executionCancelledAt":null,"executionTime":575,"lastExecutedAt":1697074520009,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import nltk\nnltk.download('punkt')","outputsMetadata":{"0":{"height":56,"type":"stream"}}},"cell_type":"code","id":"cac13b67-d720-49c5-a5e2-cd07d94a5836","execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":"[nltk_data] Downloading package punkt to /home/repl/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n"},{"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{},"execution_count":2}]},{"source":"# nltk functions and methods for tokenization\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import regexp_tokenize\nfrom nltk.tokenize import TweetTokenizer","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1697074530704,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# nltk functions and methods for tokenization\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.tokenize import word_tokenize\nfrom nltk.tokenize import regexp_tokenize\nfrom nltk.tokenize import TweetTokenizer"},"cell_type":"code","id":"baf9b10e-a338-4196-b474-1f86ec6e376e","execution_count":3,"outputs":[]},{"source":"chat_gpt = \"ChatGPT is a sibling model to InstructGPT, which is trained to follow an instruction in a prompt and provide a detailed response. We are excited to introduce ChatGPT to get users‚Äô feedback and learn about its strengths and weaknesses. During the research preview, usage of ChatGPT is free. Try it now at chat.openai.com. #ChatGPT #InstructGPT  #OpenAI #ChatGPTisFree\"","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1697074538353,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"chat_gpt = \"ChatGPT is a sibling model to InstructGPT, which is trained to follow an instruction in a prompt and provide a detailed response. We are excited to introduce ChatGPT to get users‚Äô feedback and learn about its strengths and weaknesses. During the research preview, usage of ChatGPT is free. Try it now at chat.openai.com. #ChatGPT #InstructGPT  #OpenAI #ChatGPTisFree\""},"id":"c35a7032-166b-4cd8-a671-1865cd39a5e0","cell_type":"code","execution_count":4,"outputs":[]},{"source":"# from nltk.tokenize import sent_tokenize\nchatgpt_sents = sent_tokenize(chat_gpt)\nfor line in chatgpt_sents:\n    print(line,\"\\n\")","metadata":{"executionCancelledAt":null,"executionTime":20,"lastExecutedAt":1697074547540,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# from nltk.tokenize import sent_tokenize\nchatgpt_sents = sent_tokenize(chat_gpt)\nfor line in chatgpt_sents:\n    print(line,\"\\n\")","outputsMetadata":{"0":{"height":212,"type":"stream"}}},"id":"520f50c5-6d90-4824-aa27-7bc3e394d0f3","cell_type":"code","execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":"ChatGPT is a sibling model to InstructGPT, which is trained to follow an instruction in a prompt and provide a detailed response. \n\nWe are excited to introduce ChatGPT to get users‚Äô feedback and learn about its strengths and weaknesses. \n\nDuring the research preview, usage of ChatGPT is free. \n\nTry it now at chat.openai.com. \n\n#ChatGPT #InstructGPT  #OpenAI #ChatGPTisFree \n\n"}]},{"source":"# from nltk.tokenize import word_tokenize\nchatgpt_words_v1 = word_tokenize(chat_gpt)\nprint(chatgpt_words_v1)","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1697074594973,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# from nltk.tokenize import word_tokenize\nchatgpt_words_v1 = word_tokenize(chat_gpt)\nprint(chatgpt_words_v1)","outputsMetadata":{"0":{"height":114,"type":"stream"}}},"id":"73b65c99-4059-449f-9a83-fa1c09d8aa1e","cell_type":"code","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":"['ChatGPT', 'is', 'a', 'sibling', 'model', 'to', 'InstructGPT', ',', 'which', 'is', 'trained', 'to', 'follow', 'an', 'instruction', 'in', 'a', 'prompt', 'and', 'provide', 'a', 'detailed', 'response', '.', 'We', 'are', 'excited', 'to', 'introduce', 'ChatGPT', 'to', 'get', 'users', '‚Äô', 'feedback', 'and', 'learn', 'about', 'its', 'strengths', 'and', 'weaknesses', '.', 'During', 'the', 'research', 'preview', ',', 'usage', 'of', 'ChatGPT', 'is', 'free', '.', 'Try', 'it', 'now', 'at', 'chat.openai.com', '.', '#', 'ChatGPT', '#', 'InstructGPT', '#', 'OpenAI', '#', 'ChatGPTisFree']\n"}]},{"source":"#from nltk.tokenize import regexp_tokenize\n\nchatgpt_words_v2 = regexp_tokenize(chat_gpt, r\"([\\@|#]\\w+|\\w+)\")\nprint(chatgpt_words_v2)\n","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1697074679006,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#from nltk.tokenize import regexp_tokenize\n\nchatgpt_words_v2 = regexp_tokenize(chat_gpt, r\"([\\@|#]\\w+|\\w+)\")\nprint(chatgpt_words_v2)\n","outputsMetadata":{"0":{"height":114,"type":"stream"}}},"id":"227557d4-3504-4fb3-8018-2305e0243475","cell_type":"code","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":"['ChatGPT', 'is', 'a', 'sibling', 'model', 'to', 'InstructGPT', 'which', 'is', 'trained', 'to', 'follow', 'an', 'instruction', 'in', 'a', 'prompt', 'and', 'provide', 'a', 'detailed', 'response', 'We', 'are', 'excited', 'to', 'introduce', 'ChatGPT', 'to', 'get', 'users', 'feedback', 'and', 'learn', 'about', 'its', 'strengths', 'and', 'weaknesses', 'During', 'the', 'research', 'preview', 'usage', 'of', 'ChatGPT', 'is', 'free', 'Try', 'it', 'now', 'at', 'chat', 'openai', 'com', '#ChatGPT', '#InstructGPT', '#OpenAI', '#ChatGPTisFree']\n"}]},{"source":"# Initialize TweetTokenizer\ntknzr = TweetTokenizer()\nchatgpt_words_v3 = tknzr.tokenize(chat_gpt)\nprint(chatgpt_words_v3)","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1697074807582,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initialize TweetTokenizer\ntknzr = TweetTokenizer()\nchatgpt_words_v3 = tknzr.tokenize(chat_gpt)\nprint(chatgpt_words_v3)","outputsMetadata":{"0":{"height":114,"type":"stream"}}},"cell_type":"code","id":"f5d11c64-87e8-40e2-8521-20a70d0fa81b","execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":"['ChatGPT', 'is', 'a', 'sibling', 'model', 'to', 'InstructGPT', ',', 'which', 'is', 'trained', 'to', 'follow', 'an', 'instruction', 'in', 'a', 'prompt', 'and', 'provide', 'a', 'detailed', 'response', '.', 'We', 'are', 'excited', 'to', 'introduce', 'ChatGPT', 'to', 'get', 'users', '‚Äô', 'feedback', 'and', 'learn', 'about', 'its', 'strengths', 'and', 'weaknesses', '.', 'During', 'the', 'research', 'preview', ',', 'usage', 'of', 'ChatGPT', 'is', 'free', '.', 'Try', 'it', 'now', 'at', 'chat.openai.com', '.', '#ChatGPT', '#InstructGPT', '#OpenAI', '#ChatGPTisFree']\n"}]},{"source":"### Tokenizing with n-grams\n\n`N-gram` can be defined as the contiguous sequence of `n` items from a given sample of text or speech. The items can be letters, words, or base pairs according to the application.","metadata":{},"cell_type":"markdown","id":"3e2b307f-839e-441d-95e4-1641871b63a0"},{"source":"First, we tokenize into a sentence in a document.","metadata":{},"cell_type":"markdown","id":"959ccbe1-7662-4177-9ca5-78f7f98fec61"},{"source":"from nltk.util import ngrams\n\nchatgpt_words_in_sent = [word_tokenize(sentence) for sentence in chatgpt_sents]\nchatgpt_bigrams = []\nfor tokens in chatgpt_words_in_sent:\n    bigram = ngrams(tokens, 2)\n    chatgpt_bigrams.extend(list(bigram))\n\nunzipped_bigrams = list(zip(*chatgpt_bigrams))\nprint(unzipped_bigrams)","metadata":{"executionCancelledAt":null,"executionTime":15,"lastExecutedAt":1697075126143,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from nltk.util import ngrams\n\nchatgpt_words_in_sent = [word_tokenize(sentence) for sentence in chatgpt_sents]\nchatgpt_bigrams = []\nfor tokens in chatgpt_words_in_sent:\n    bigram = ngrams(tokens, 2)\n    chatgpt_bigrams.extend(list(bigram))\n\nunzipped_bigrams = list(zip(*chatgpt_bigrams))\nprint(unzipped_bigrams)","outputsMetadata":{"0":{"height":192,"type":"stream"}}},"cell_type":"code","id":"22d4afb8-7179-45f2-bf4a-5de4bdc7725c","execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":"[('ChatGPT', 'is', 'a', 'sibling', 'model', 'to', 'InstructGPT', ',', 'which', 'is', 'trained', 'to', 'follow', 'an', 'instruction', 'in', 'a', 'prompt', 'and', 'provide', 'a', 'detailed', 'response', 'We', 'are', 'excited', 'to', 'introduce', 'ChatGPT', 'to', 'get', 'users', '‚Äô', 'feedback', 'and', 'learn', 'about', 'its', 'strengths', 'and', 'weaknesses', 'During', 'the', 'research', 'preview', ',', 'usage', 'of', 'ChatGPT', 'is', 'free', 'Try', 'it', 'now', 'at', 'chat.openai.com', '#', 'ChatGPT', '#', 'InstructGPT', '#', 'OpenAI', '#'), ('is', 'a', 'sibling', 'model', 'to', 'InstructGPT', ',', 'which', 'is', 'trained', 'to', 'follow', 'an', 'instruction', 'in', 'a', 'prompt', 'and', 'provide', 'a', 'detailed', 'response', '.', 'are', 'excited', 'to', 'introduce', 'ChatGPT', 'to', 'get', 'users', '‚Äô', 'feedback', 'and', 'learn', 'about', 'its', 'strengths', 'and', 'weaknesses', '.', 'the', 'research', 'preview', ',', 'usage', 'of', 'ChatGPT', 'is', 'free', '.', 'it', 'now', 'at', 'chat.openai.com', '.', 'ChatGPT', '#', 'InstructGPT', '#', 'OpenAI', '#', 'ChatGPTisFree')]\n"}]},{"source":"# import nltk\nfrom nltk.util import ngrams\n\ntext = \"Hi How are you? I am fine and you\"\ntokens = nltk.word_tokenize(text)\n\n# Tokenizing with bigrams\nbigrams = list(ngrams(tokens, 2))\n\n# print the bigrams of the text\nunzipped_bigrams = list(zip(*bigrams))\nfor i in range(len(bigrams)):\n    print(unzipped_bigrams[0][i],unzipped_bigrams[1][i])","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1697075220489,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# import nltk\nfrom nltk.util import ngrams\n\ntext = \"Hi How are you? I am fine and you\"\ntokens = nltk.word_tokenize(text)\n\n# Tokenizing with bigrams\nbigrams = list(ngrams(tokens, 2))\n\n# print the bigrams of the text\nunzipped_bigrams = list(zip(*bigrams))\nfor i in range(len(bigrams)):\n    print(unzipped_bigrams[0][i],unzipped_bigrams[1][i])","outputsMetadata":{"0":{"height":192,"type":"stream"}}},"cell_type":"code","id":"bb17bbf9-18f7-4fb4-a6bb-1f4bed88efaf","execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":"Hi How\nHow are\nare you\nyou ?\n? I\nI am\nam fine\nfine and\nand you\n"}]},{"source":"# Tokenizing with trigrams\ntrigrams = list(ngrams(tokens, 3))\n\n# print the trigrams of the text\nunzipped_trigrams = list(zip(*trigrams))\nfor i in range(len(trigrams)):\n    print(unzipped_trigrams[0][i],unzipped_trigrams[1][i], unzipped_trigrams[2][i])","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":173,"type":"stream"}},"collapsed":false,"jupyter":{"outputs_hidden":false,"source_hidden":false}},"cell_type":"code","id":"8f954803-c868-4a83-83a1-4376aa65e660","execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":"Hi How are\nHow are you\nare you ?\nyou ? I\n? I am\nI am fine\nam fine and\nfine and you\n"}]},{"source":"### Extracting words with 1st letter capitalized","metadata":{},"cell_type":"markdown","id":"5c20b680-955e-4e4c-af41-0b37ffca05ff"},{"source":"for line in chatgpt_sents:\n    print(regexp_tokenize(line, r\"[A-Z]\\w+\"))","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1697075380598,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"for line in chatgpt_sents:\n    print(regexp_tokenize(line, r\"[A-Z]\\w+\"))","outputsMetadata":{"0":{"height":114,"type":"stream"}}},"id":"7e474e42-7265-43a2-a02d-a49ff6a71732","cell_type":"code","execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":"['ChatGPT', 'InstructGPT']\n['We', 'ChatGPT']\n['During', 'ChatGPT']\n['Try']\n['ChatGPT', 'InstructGPT', 'OpenAI', 'ChatGPTisFree']\n"}]},{"source":"### Extracting hashtags and emoji","metadata":{},"cell_type":"markdown","id":"75266a6f-aecb-4777-a57c-cd0751bd047c"},{"source":"# Ernest Obiena's facebook page. Posted by Djundi Bi√±as\nmessage2 = \"\"\"Congratulations Ernest Obiena EJ Obiena - Ernest Obiena for Winning the 1st Gold ü•áMedal for the Philippines üáµüá≠ in the 19th Asian Games and breaking the Championship Record! üí™üèºüíØ Boom! üí•Salamat EJ \n#ParaSaBayan \n#PoleVault \n#PhilippinePoleVault \n#TheEJEffectCongratulations Ernest Obiena EJ Obiena - Ernest Obiena for Winning the 1st Gold ü•áMedal for the Philippines üáµüá≠ in the 19th Asian Games and breaking the Championship Record! üí™üèºüíØ Boom! üí•Salamat EJ ü´∞üèºüôåüèº\n#ParaSaBayan \n#PoleVault \n#PhilippinePoleVault \n#TheEJEffect\"\"\"\n# message2","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1697075415653,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Ernest Obiena's facebook page. Posted by Djundi Bi√±as\nmessage2 = \"\"\"Congratulations Ernest Obiena EJ Obiena - Ernest Obiena for Winning the 1st Gold ü•áMedal for the Philippines üáµüá≠ in the 19th Asian Games and breaking the Championship Record! üí™üèºüíØ Boom! üí•Salamat EJ \n#ParaSaBayan \n#PoleVault \n#PhilippinePoleVault \n#TheEJEffectCongratulations Ernest Obiena EJ Obiena - Ernest Obiena for Winning the 1st Gold ü•áMedal for the Philippines üáµüá≠ in the 19th Asian Games and breaking the Championship Record! üí™üèºüíØ Boom! üí•Salamat EJ ü´∞üèºüôåüèº\n#ParaSaBayan \n#PoleVault \n#PhilippinePoleVault \n#TheEJEffect\"\"\"\n# message2"},"id":"89d4dc0c-fb7d-4fb7-966d-359c74957fac","cell_type":"code","execution_count":17,"outputs":[]},{"source":"# Tokenizing all hashtags\nregexp_tokenize(message2, r\"#\\w+\")","metadata":{"executionCancelledAt":null,"executionTime":13,"lastExecutedAt":1697075427494,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Tokenizing all hashtags\nregexp_tokenize(message2, r\"#\\w+\")"},"id":"70840d08-380a-4749-8c3b-b9ba096d0e00","cell_type":"code","execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":"['#ParaSaBayan',\n '#PoleVault',\n '#PhilippinePoleVault',\n '#TheEJEffectCongratulations',\n '#ParaSaBayan',\n '#PoleVault',\n '#PhilippinePoleVault',\n '#TheEJEffect']"},"metadata":{},"execution_count":18}]},{"source":"# Tokenize emojis  using NLTK\nemoji_pattern = r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U0001FAB0-\\U0001FABF\\U0001FAC0-\\U0001FAFF\\U00002600-\\U000026FF]+'\n\nemojis = regexp_tokenize(message2, emoji_pattern)\n\nfor emoji in emojis:\n    print(emoji, end='')","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1697075456450,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Tokenize emojis  using NLTK\nemoji_pattern = r'[\\U0001F600-\\U0001F64F\\U0001F300-\\U0001F5FF\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U0001FAB0-\\U0001FABF\\U0001FAC0-\\U0001FAFF\\U00002600-\\U000026FF]+'\n\nemojis = regexp_tokenize(message2, emoji_pattern)\n\nfor emoji in emojis:\n    print(emoji, end='')","outputsMetadata":{"0":{"height":36,"type":"stream"}}},"id":"fdfff852-faee-4ae1-a5dc-473176a8e964","cell_type":"code","execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":"ü•áüí™üèºüíØüí•ü•áüí™üèºüíØüí•ü´∞üèºüôåüèº"}]},{"source":"## Processing from raw text to cleaned text\n\n\"clean text\" or \"cleaned text\" typically refers to text data that has been processed to remove any elements that are considered irrelevant or noise for a specific NLP task. \n\nThe cleaning process can include several steps, such as:\n\n*   **Lowercasing**: Converting all text to lowercase to ensure consistency and reduce the dimensionality of the data.\n\n*   **Tokenization**: Breaking the text into individual words or tokens.\n\n*   **Stopword Removal**: Eliminating common words (e.g., \"and,\" \"the,\" \"is\") that may not carry significant meaning for the task at hand.\n\n*   **Punctuation Removal**: Stripping punctuation marks from the text.\n\n*   **Lemmatization** or **Stemming**: Reducing words to their base or root forms. Lemmatization typically produces real words, while stemming may result in non-real words but is computationally less intensive.\n\n*   **Special Character Removal**: Removing special characters, numbers, or symbols that are not relevant to the analysis.\n\n*   **Spell Correction**: Fixing common spelling errors in the text.\n\n*   **Noise Reduction**: Handling additional data-specific noise, such as HTML tags in web text or emojis in social media text.","metadata":{},"id":"d95b9856-3403-4342-8802-01938bbff4c1","cell_type":"markdown"},{"source":"### Removing punctuation from a string with regex starting from the raw text data","metadata":{},"cell_type":"markdown","id":"0a66908d-a6a2-4f69-8321-3f7e9bc73f16"},{"source":"no_punc = re.sub(r'[^\\w\\s]', '', chat_gpt)\nno_punc","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1697075706002,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"no_punc = re.sub(r'[^\\w\\s]', '', chat_gpt)\nno_punc"},"cell_type":"code","id":"d9beb49d-7152-4e2a-b5a0-3fb99c4d0c4f","execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":"'ChatGPT is a sibling model to InstructGPT which is trained to follow an instruction in a prompt and provide a detailed response We are excited to introduce ChatGPT to get users feedback and learn about its strengths and weaknesses During the research preview usage of ChatGPT is free Try it now at chatopenaicom ChatGPT InstructGPT  OpenAI ChatGPTisFree'"},"metadata":{},"execution_count":20}]},{"source":"### Lowercasing from a string after punctuation removal","metadata":{},"cell_type":"markdown","id":"1ea5bab2-3025-42da-9bc7-5ed63057e8b8"},{"source":"lowercase_no_punc = no_punc.lower()\nlowercase_no_punc","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1697075750206,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"lowercase_no_punc = no_punc.lower()\nlowercase_no_punc"},"cell_type":"code","id":"48d0bfb1-0fe5-472c-bacd-0a965360c216","execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":"'chatgpt is a sibling model to instructgpt which is trained to follow an instruction in a prompt and provide a detailed response we are excited to introduce chatgpt to get users feedback and learn about its strengths and weaknesses during the research preview usage of chatgpt is free try it now at chatopenaicom chatgpt instructgpt  openai chatgptisfree'"},"metadata":{},"execution_count":21}]},{"source":"print(word_tokenize(lowercase_no_punc))","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1697075764122,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(word_tokenize(lowercase_no_punc))","outputsMetadata":{"0":{"height":114,"type":"stream"}}},"cell_type":"code","id":"68da3eca-e4cc-47ab-9a46-1ea63ae113e9","execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":"['chatgpt', 'is', 'a', 'sibling', 'model', 'to', 'instructgpt', 'which', 'is', 'trained', 'to', 'follow', 'an', 'instruction', 'in', 'a', 'prompt', 'and', 'provide', 'a', 'detailed', 'response', 'we', 'are', 'excited', 'to', 'introduce', 'chatgpt', 'to', 'get', 'users', 'feedback', 'and', 'learn', 'about', 'its', 'strengths', 'and', 'weaknesses', 'during', 'the', 'research', 'preview', 'usage', 'of', 'chatgpt', 'is', 'free', 'try', 'it', 'now', 'at', 'chatopenaicom', 'chatgpt', 'instructgpt', 'openai', 'chatgptisfree']\n"}]},{"source":"print(regexp_tokenize(lowercase_no_punc, r\"([\\@|#]\\w+|\\w+)\"))","metadata":{"executionCancelledAt":null,"executionTime":13,"lastExecutedAt":1697075769753,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(regexp_tokenize(lowercase_no_punc, r\"([\\@|#]\\w+|\\w+)\"))","outputsMetadata":{"0":{"height":114,"type":"stream"}}},"cell_type":"code","id":"84f583b2-808e-4b01-bc86-361d0e9dda41","execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":"['chatgpt', 'is', 'a', 'sibling', 'model', 'to', 'instructgpt', 'which', 'is', 'trained', 'to', 'follow', 'an', 'instruction', 'in', 'a', 'prompt', 'and', 'provide', 'a', 'detailed', 'response', 'we', 'are', 'excited', 'to', 'introduce', 'chatgpt', 'to', 'get', 'users', 'feedback', 'and', 'learn', 'about', 'its', 'strengths', 'and', 'weaknesses', 'during', 'the', 'research', 'preview', 'usage', 'of', 'chatgpt', 'is', 'free', 'try', 'it', 'now', 'at', 'chatopenaicom', 'chatgpt', 'instructgpt', 'openai', 'chatgptisfree']\n"}]},{"source":"print(tknzr.tokenize(lowercase_no_punc))","metadata":{"executionCancelledAt":null,"executionTime":14,"lastExecutedAt":1697075773246,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(tknzr.tokenize(lowercase_no_punc))","outputsMetadata":{"0":{"height":114,"type":"stream"}}},"cell_type":"code","id":"fc064407-d580-43dc-b388-b7142ed43918","execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":"['chatgpt', 'is', 'a', 'sibling', 'model', 'to', 'instructgpt', 'which', 'is', 'trained', 'to', 'follow', 'an', 'instruction', 'in', 'a', 'prompt', 'and', 'provide', 'a', 'detailed', 'response', 'we', 'are', 'excited', 'to', 'introduce', 'chatgpt', 'to', 'get', 'users', 'feedback', 'and', 'learn', 'about', 'its', 'strengths', 'and', 'weaknesses', 'during', 'the', 'research', 'preview', 'usage', 'of', 'chatgpt', 'is', 'free', 'try', 'it', 'now', 'at', 'chatopenaicom', 'chatgpt', 'instructgpt', 'openai', 'chatgptisfree']\n"}]},{"source":"### Removing stopwords","metadata":{},"cell_type":"markdown","id":"24fb56cc-d372-4f57-a732-8bff31e66394"},{"source":"from nltk.corpus import stopwords\n \nnltk.download('stopwords')\nprint(stopwords.words('english'))","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":251,"type":"stream"},"1":{"height":56,"type":"stream"}}},"cell_type":"code","id":"f91d402d-6e21-4ea1-ac98-e0a330428747","execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":"['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"},{"output_type":"stream","name":"stderr","text":"[nltk_data] Downloading package stopwords to /home/repl/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"}]},{"source":"def set_clean(raw_text):\n    set_stop_words = set(stopwords.words('english'))\n    \n    no_punc = re.sub(r'[^\\w\\s]', '', raw_text)\n    lowercase_no_punc = no_punc.lower()\n    tokenized_text= word_tokenize(lowercase_no_punc)\n    return [w for w in tokenized_text if w not in set_stop_words]","metadata":{"executionCancelledAt":null,"executionTime":11,"lastExecutedAt":1697076030584,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"def set_clean(raw_text):\n    set_stop_words = set(stopwords.words('english'))\n    \n    no_punc = re.sub(r'[^\\w\\s]', '', raw_text)\n    lowercase_no_punc = no_punc.lower()\n    tokenized_text= word_tokenize(lowercase_no_punc)\n    return [w for w in tokenized_text if w not in set_stop_words]"},"cell_type":"code","id":"f78b2927-2f2a-42ce-a43f-729db89d8da6","execution_count":32,"outputs":[]},{"source":"clean_tokenized_text = set_clean(chat_gpt)\nprint(clean_tokenized_text)","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1697076034286,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"clean_tokenized_text = set_clean(chat_gpt)\nprint(clean_tokenized_text)","outputsMetadata":{"0":{"height":75,"type":"stream"}}},"cell_type":"code","id":"060f11fd-b1e9-4258-8a22-83d062f7615e","execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":"['chatgpt', 'sibling', 'model', 'instructgpt', 'trained', 'follow', 'instruction', 'prompt', 'provide', 'detailed', 'response', 'excited', 'introduce', 'chatgpt', 'get', 'users', 'feedback', 'learn', 'strengths', 'weaknesses', 'research', 'preview', 'usage', 'chatgpt', 'free', 'try', 'chatopenaicom', 'chatgpt', 'instructgpt', 'openai', 'chatgptisfree']\n"}]},{"source":"print(len(chatgpt_words_v1), len(chatgpt_words_v2), len(chatgpt_words_v3), len(clean_tokenized_text))","metadata":{"executionCancelledAt":null,"executionTime":14,"lastExecutedAt":1697076063271,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(len(chatgpt_words_v1), len(chatgpt_words_v2), len(chatgpt_words_v3), len(clean_tokenized_text))","outputsMetadata":{"0":{"height":36,"type":"stream"}}},"cell_type":"code","id":"f4421afd-05a1-4270-ac19-1f66e770f691","execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":"68 59 64 31\n"}]},{"source":"### On stemming and lemmatization\n\n**Stemming** is the process of producing morphological variants of a root/base word. \n\n*  stemming programs are commonly referred to as stemming algorithms or stemmers. \n*  Example: `boat` would be the stem for `boat`, `boater`, `boating`, `boats`.\n\n**Lemmatization** looks beyond word reduction and considers a language‚Äôs full vocabulary to apply a morphological analysis to words. *  Example: The lemma of`‚Äòwas` is `be` and the lemma of `mice` is `mouse`.","metadata":{},"cell_type":"markdown","id":"8caa81e5-3667-4a53-8759-9e349f2c7b17"},{"source":"from nltk.stem import PorterStemmer\nstemmer = PorterStemmer()\nprint(\"stem for boating: \", stemmer.stem(\"boating\"))\nprint(\"stem for running: \", stemmer.stem(\"running\"))\nprint(\"stem for better: \", stemmer.stem(\"better\"))\nprint(\"stem for mice: \", stemmer.stem(\"mice\"))","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1697076454665,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from nltk.stem import PorterStemmer\nstemmer = PorterStemmer()\nprint(\"stem for boating: \", stemmer.stem(\"boating\"))\nprint(\"stem for running: \", stemmer.stem(\"running\"))\nprint(\"stem for better: \", stemmer.stem(\"better\"))\nprint(\"stem for mice: \", stemmer.stem(\"mice\"))","outputsMetadata":{"0":{"height":95,"type":"stream"}}},"cell_type":"code","id":"65be4408-4fb5-40a1-8dcf-e8e71e878730","execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":"stem for boating:  boat\nstem for running:  run\nstem for better:  better\nstem for mice:  mice\n"}]},{"source":"#import nltk\nnltk.download('wordnet')\nnltk.download('omw-1.4')","metadata":{"executionCancelledAt":null,"executionTime":70,"lastExecutedAt":1697076238179,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#import nltk\nnltk.download('wordnet')\nnltk.download('omw-1.4')","outputsMetadata":{"0":{"height":95,"type":"stream"},"1":{"height":95,"type":"stream"}}},"cell_type":"code","id":"80159987-ed23-4e6a-999a-a26ddb489a62","execution_count":36,"outputs":[{"output_type":"stream","name":"stderr","text":"[nltk_data] Downloading package wordnet to /home/repl/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /home/repl/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n"},{"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{},"execution_count":36}]},{"source":"from nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\n\nprint(\"lemma for boating: \", lemmatizer.lemmatize(\"boating\", pos=\"v\"))\nprint(\"lemma for running: \", lemmatizer.lemmatize(\"running\", pos=\"v\"))\nprint(\"lemma for better: \", lemmatizer.lemmatize(\"better\", pos=\"a\"))\nprint(\"lemma for mice: \", lemmatizer.lemmatize(\"mice\", pos=\"n\"))","metadata":{"executionCancelledAt":null,"executionTime":1420,"lastExecutedAt":1697076290569,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"from nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\n\nprint(\"lemma for boating: \", lemmatizer.lemmatize(\"boating\", pos=\"v\"))\nprint(\"lemma for running: \", lemmatizer.lemmatize(\"running\", pos=\"v\"))\nprint(\"lemma for better: \", lemmatizer.lemmatize(\"better\", pos=\"a\"))\nprint(\"lemma for mice: \", lemmatizer.lemmatize(\"mice\", pos=\"n\"))","outputsMetadata":{"0":{"height":95,"type":"stream"}}},"cell_type":"code","id":"57434b7d-de05-4f27-9fce-dce2c9bad697","execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":"lemma for boating:  boat\nlemma for running:  run\nlemma for better:  good\nlemma for mice:  mouse\n"}]},{"source":"print(\"lemma for matrices: \", lemmatizer.lemmatize(\"matrices\", pos=\"n\"))\nprint(\"stem for matrices: \", stemmer.stem(\"matrices\"))","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1697076422965,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(\"lemma for matrices: \", lemmatizer.lemmatize(\"matrices\", pos=\"n\"))\nprint(\"stem for matrices: \", stemmer.stem(\"matrices\"))","outputsMetadata":{"0":{"height":56,"type":"stream"}}},"cell_type":"code","id":"7a160313-dcc7-4072-9f2a-455773a3fe17","execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":"lemma for matrices:  matrix\nstem for matrices:  matric\n"}]},{"source":"with open(\"datasets/wiki_text_debugging.txt\", \"r\") as file:\n    wiki_text = file.read()\n\nwiki_text[:500]","cell_type":"code","id":"22d36fa3-9053-4f13-97c4-040657561fe2","outputs":[{"output_type":"execute_result","data":{"text/plain":"\"'''Debugging''' is the process of finding and resolving of defects that prevent correct operation of computer software or a system.  \\n\\nNumerous books have been written about debugging (see below: #Further reading|Further reading), as it involves numerous aspects, including interactive debugging, control flow, integration testing, Logfile|log files, monitoring (Application monitoring|application, System Monitoring|system), memory dumps, Profiling (computer programming)|profiling, Statistical Proc\""},"metadata":{},"execution_count":45}],"metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1697076653590,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"with open(\"datasets/wiki_text_debugging.txt\", \"r\") as file:\n    wiki_text = file.read()\n\nwiki_text[:500]","outputsMetadata":{"0":{"height":193,"type":"dataFrame"}}},"execution_count":45},{"source":"clean_wiki_text = set_clean(wiki_text)\nprint(clean_wiki_text[:50])","metadata":{"executionCancelledAt":null,"executionTime":51,"lastExecutedAt":1697076497130,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"clean_wiki_text = set_clean(wiki_text)\nprint(clean_wiki_text[:50])","outputsMetadata":{"0":{"height":114,"type":"stream"}}},"cell_type":"code","id":"888f49ca-9fce-4feb-b81c-e1be4bcc6237","execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":"['debugging', 'process', 'finding', 'resolving', 'defects', 'prevent', 'correct', 'operation', 'computer', 'software', 'system', 'numerous', 'books', 'written', 'debugging', 'see', 'readingfurther', 'reading', 'involves', 'numerous', 'aspects', 'including', 'interactive', 'debugging', 'control', 'flow', 'integration', 'testing', 'logfilelog', 'files', 'monitoring', 'application', 'monitoringapplication', 'system', 'monitoringsystem', 'memory', 'dumps', 'profiling', 'computer', 'programmingprofiling', 'statistical', 'process', 'control', 'special', 'design', 'tactics', 'improve', 'detection', 'simplifying', 'changes']\n"}]},{"source":"lc_wiki_text = [lemmatizer.lemmatize(word, pos=\"v\") for word in clean_wiki_text]\nlc_wiki_text = [lemmatizer.lemmatize(word, pos=\"n\") for word in lc_wiki_text]\nlc_wiki_text = [lemmatizer.lemmatize(word, pos=\"a\") for word in lc_wiki_text]\nlc_wiki_text = [lemmatizer.lemmatize(word, pos=\"r\") for word in lc_wiki_text]\nlc_wiki_text = [lemmatizer.lemmatize(word, pos=\"s\") for word in lc_wiki_text]\nprint(lc_wiki_text[:50])","metadata":{"executionCancelledAt":null,"executionTime":63,"lastExecutedAt":1697076559205,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"lc_wiki_text = [lemmatizer.lemmatize(word, pos=\"v\") for word in clean_wiki_text]\nlc_wiki_text = [lemmatizer.lemmatize(word, pos=\"n\") for word in lc_wiki_text]\nlc_wiki_text = [lemmatizer.lemmatize(word, pos=\"a\") for word in lc_wiki_text]\nlc_wiki_text = [lemmatizer.lemmatize(word, pos=\"r\") for word in lc_wiki_text]\nlc_wiki_text = [lemmatizer.lemmatize(word, pos=\"s\") for word in lc_wiki_text]\nprint(lc_wiki_text[:50])","outputsMetadata":{"0":{"height":114,"type":"stream"}}},"cell_type":"code","id":"d995e699-ef0c-4c0e-b4ff-9d25f849ae3e","execution_count":44,"outputs":[{"output_type":"stream","name":"stdout","text":"['debug', 'process', 'find', 'resolve', 'defect', 'prevent', 'correct', 'operation', 'computer', 'software', 'system', 'numerous', 'book', 'write', 'debug', 'see', 'readingfurther', 'read', 'involve', 'numerous', 'aspect', 'include', 'interactive', 'debug', 'control', 'flow', 'integration', 'test', 'logfilelog', 'file', 'monitor', 'application', 'monitoringapplication', 'system', 'monitoringsystem', 'memory', 'dump', 'profile', 'computer', 'programmingprofiling', 'statistical', 'process', 'control', 'special', 'design', 'tactic', 'improve', 'detection', 'simplify', 'change']\n"}]},{"source":"** Possible values in the `pos` parameter:**\n\n*   `n` for noun files,\n*   `v` for verb files,\n*   `a` for adjective files,\n*   `s` for adjective (satellite) files,\n*   `r` for adverb files.","metadata":{},"cell_type":"markdown","id":"043d7390-bd24-4aa5-95a6-8319627a75f7"},{"source":"","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1697021269287,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":""},"cell_type":"code","id":"b6fbc360-dbb8-4f03-b8f4-fb43dc7f8c1a","execution_count":30,"outputs":[]}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}