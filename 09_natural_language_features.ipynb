{"cells":[{"source":"","metadata":{},"cell_type":"markdown","id":"740cc594-8eff-4f99-96c1-bf01563ed641"},{"source":"# Module 3 - Natural Language Features\n\n**Our Goal** To build a supervised machine learning models for text data.\n\n1. What is a machine learning model?\n\nA machine learning model is a program that can find patterns or make decisions on a previously unseen dataset.\n\n3. What is a supervised learning?\n\nSupervised learning or supervised machine learning is the use of labeled datasets to train models for classifying data or for predicting outcomes accurately.\n\n4. What are the core components of supervised learning?\n\n*   **Data**:  A type of dataset with input-output pairs.\n*   **Model**: A mathematical function used to make predictions.\n*   **Loss Function**:  A function that quantifies how well the model is performing.\n*   **Optimization**: The model is adjusted to minimize the loss function using optimization techniques.\n\n5. What are the types of supervised machine learning?\n\n*  **Classification**: The goal is to categorize data into discrete classes.\n*  **Regression**:  The goal is to predict a continuous numerical value.\n\n6. What is supervised learning for text analysis?\n\n*  Supervised machine learning for text analysis is a subfield of natural language processing (NLP) where machine learning models or algorithms are trained to analyze and make predictions about text data. \n\n*   In supervised learning, the algorithms learn from a labeled dataset, which means that each input text sample is associated with a known outcome or label. \n\n*   The primary goal of supervised text analysis is to build models that can automatically *categorize*, *classify*, *extract information*, or *make predictions* about new, *unseen text data* based on patterns and relationships learned from the *training data*.\n\n7.  What are the steps involve in the process of supervised text analysis?\n\n    a)  **Data Collection**: Gather a labeled dataset that includes text samples with corresponding labels or outcomes.\n\n    b)  **Data Preprocessing**: Clean and preprocess the text data by *removing noise*, *tokenizing*, *stemming*, *lemmatizing*, and *converting text into numerical features*.\n\n    c)  **Feature Engineering**: Select or engineer relevant features that represent the text data effectively. This step is crucial for model performance.\n\n    d)  **Model Selection**: Choose an appropriate machine learning algorithm or deep learning architecture for the specific text analysis task. \n\n       *  Common choices include *support vector machines* (SVM), *decision trees*, *random forests*, and *neural networks* (e.g., LSTM, Transformer).\n\n    e)  **Model Training**: Train the selected model on the labeled dataset, adjusting model parameters to minimize a chosen loss function.\n\n    f)  **Evaluation**: Assess the model's performance using evaluation metrics such as *accuracy*, *precision*, *recall*, *F1-score*, or *mean squared error* (depending on the task).\n\n    g)  **Deployment**: Deploy the trained model in real-world applications for automated text analysis.\n\n8)  What are the sections in this module?\n\n   *  **Tokenization** \n  \n   *  **Stopwords and Stemming** \n\n   *  **Word Embeddings**\n\n**Exam 3 - October 12, 2023  (100 pts)**\n\n","metadata":{},"cell_type":"markdown","id":"8a3abf61-6fd0-4003-88f9-0efd1962f4da"},{"source":"","metadata":{},"cell_type":"markdown","id":"b948bc85-9092-42ce-86c0-8320e5570de4"}],"metadata":{"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}